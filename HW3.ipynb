{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Реализуйте алгоритм GAIL на среде Mountain Car. Перед этим сгенерируйте экспертные данные (из детерминированной стратегии с первой практики). Хорошей идеей будет добавить в state (observation) синус и косинус от временной метки t для лучшего обучения."
      ],
      "metadata": {
        "id": "EPGPfi8EajGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.distributions.categorical import Categorical\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "LB3tAmdwDYmk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"MountainCar-v0\")"
      ],
      "metadata": {
        "id": "u6VQkZtZDhFs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_expert_data(env, num_episodes=1000):\n",
        "    states, actions = [], []\n",
        "    for _ in range(num_episodes):\n",
        "        obs, _ = env.reset()\n",
        "        done = False\n",
        "        t = 0  # Инициализация переменной времени\n",
        "        while not done:\n",
        "            # Простая детерминированная стратегия: толкать влево или вправо в зависимости от положения\n",
        "            action = 0 if obs[1] < 0 else 2\n",
        "            next_obs, _, terminated, truncated, _ = env.step(action)\n",
        "            done = terminated or truncated\n",
        "            states.append(np.append(obs, [np.sin(t), np.cos(t)]))  # Используем t вместо _\n",
        "            actions.append(action)\n",
        "            obs = next_obs\n",
        "            t += 1  # Увеличиваем t\n",
        "    return np.array(states), np.array(actions)"
      ],
      "metadata": {
        "id": "jvorYj5WDi6M"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states, actions = generate_expert_data(env)"
      ],
      "metadata": {
        "id": "xBm0V11mEaHk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obs_dim = env.observation_space.shape[0] + 2  # +2 для синуса и косинуса временной метки\n",
        "act_dim = env.action_space.n\n",
        "expert_obs = np.copy(states)\n",
        "expert_acts = np.copy(actions)"
      ],
      "metadata": {
        "id": "VxubhK0fEcrc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Policy(nn.Module):\n",
        "    def __init__(self, obs_dim, act_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(obs_dim, 64), nn.ReLU(),\n",
        "            nn.Linear(64, act_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, obs):\n",
        "        logits = self.net(obs)\n",
        "        return Categorical(logits=logits)\n",
        "\n",
        "    def get_action(self, obs):\n",
        "        dist = self.forward(obs)\n",
        "        return dist.sample().item()"
      ],
      "metadata": {
        "id": "GOhdCyAkEkf8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, obs_dim, act_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(obs_dim + act_dim, 64), nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, obs, act):\n",
        "        act_onehot = F.one_hot(act, num_classes=act_dim).float()\n",
        "        x = torch.cat([obs, act_onehot], dim=1)\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "JO-yZaTXEmuE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrajectoryBuffer:\n",
        "    def __init__(self):\n",
        "        self.obs, self.acts, self.rews = [], [], []\n",
        "\n",
        "    def store(self, o, a, r):\n",
        "        self.obs.append(o)\n",
        "        self.acts.append(a)\n",
        "        self.rews.append(r)\n",
        "\n",
        "    def get(self):\n",
        "        return (\n",
        "            torch.tensor(np.array(self.obs), dtype=torch.float32),\n",
        "            torch.tensor(np.array(self.acts), dtype=torch.long),\n",
        "            torch.tensor(np.array(self.rews), dtype=torch.float32)\n",
        "        )"
      ],
      "metadata": {
        "id": "f_T1fMFhEoxs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "policy = Policy(obs_dim, act_dim)\n",
        "discrim = Discriminator(obs_dim, act_dim)\n",
        "policy_opt = optim.Adam(policy.parameters(), lr=1e-3)\n",
        "discrim_opt = optim.Adam(discrim.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "JJcY2UyREqyE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(3000):\n",
        "    buf = TrajectoryBuffer()\n",
        "    obs, _ = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    t = 0\n",
        "\n",
        "    while not done:\n",
        "        # Добавляем синус и косинус временной метки в состояние\n",
        "        obs_with_time = np.append(obs, [np.sin(t), np.cos(t)])\n",
        "        obs_tensor = torch.tensor(obs_with_time, dtype=torch.float32).unsqueeze(0)\n",
        "        action = policy.get_action(obs_tensor)\n",
        "        next_obs, _, terminated, truncated, _ = env.step(action)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        buf.store(obs_with_time, action, 0)\n",
        "        obs = next_obs\n",
        "        t += 1\n",
        "\n",
        "    agent_obs, agent_acts, _ = buf.get()\n",
        "\n",
        "    idxs = np.random.choice(len(expert_obs), len(agent_obs), replace=False)\n",
        "    exp_obs = torch.tensor(expert_obs[idxs], dtype=torch.float32)\n",
        "    exp_acts = torch.tensor(expert_acts[idxs], dtype=torch.long)\n",
        "\n",
        "    for _ in range(2):\n",
        "        discrim_opt.zero_grad()\n",
        "\n",
        "        discr_exp = discrim(exp_obs, exp_acts)\n",
        "        discr_ag = discrim(agent_obs, agent_acts)\n",
        "        disc_loss = -torch.mean(torch.log(discr_exp + 1e-8)) - torch.mean(torch.log(1 - discr_ag + 1e-8))\n",
        "\n",
        "        disc_loss.backward()\n",
        "        discrim_opt.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        rewards = -torch.log(1 - discrim(agent_obs, agent_acts) + 1e-8).squeeze()\n",
        "\n",
        "    policy_opt.zero_grad()\n",
        "    dist = policy(agent_obs)\n",
        "    log_probs = dist.log_prob(agent_acts)\n",
        "    loss = -(log_probs * rewards).mean()\n",
        "    loss.backward()\n",
        "    policy_opt.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}: GAIL Loss {loss.item():.3f}, Disc Loss {disc_loss.item():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02100Of4FQK0",
        "outputId": "764c5171-95ee-49d7-c028-8e90e2b6c3e7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: GAIL Loss 0.778, Disc Loss 1.414\n",
            "Epoch 10: GAIL Loss 0.732, Disc Loss 1.358\n",
            "Epoch 20: GAIL Loss 0.730, Disc Loss 1.320\n",
            "Epoch 30: GAIL Loss 0.743, Disc Loss 1.296\n",
            "Epoch 40: GAIL Loss 0.667, Disc Loss 1.255\n",
            "Epoch 50: GAIL Loss 0.613, Disc Loss 1.289\n",
            "Epoch 60: GAIL Loss 0.585, Disc Loss 1.250\n",
            "Epoch 70: GAIL Loss 0.490, Disc Loss 1.268\n",
            "Epoch 80: GAIL Loss 0.470, Disc Loss 1.284\n",
            "Epoch 90: GAIL Loss 0.455, Disc Loss 1.268\n",
            "Epoch 100: GAIL Loss 0.433, Disc Loss 1.267\n",
            "Epoch 110: GAIL Loss 0.459, Disc Loss 1.280\n",
            "Epoch 120: GAIL Loss 0.462, Disc Loss 1.252\n",
            "Epoch 130: GAIL Loss 0.481, Disc Loss 1.295\n",
            "Epoch 140: GAIL Loss 0.450, Disc Loss 1.258\n",
            "Epoch 150: GAIL Loss 0.424, Disc Loss 1.250\n",
            "Epoch 160: GAIL Loss 0.419, Disc Loss 1.237\n",
            "Epoch 170: GAIL Loss 0.431, Disc Loss 1.221\n",
            "Epoch 180: GAIL Loss 0.402, Disc Loss 1.208\n",
            "Epoch 190: GAIL Loss 0.414, Disc Loss 1.175\n",
            "Epoch 200: GAIL Loss 0.407, Disc Loss 1.156\n",
            "Epoch 210: GAIL Loss 0.364, Disc Loss 1.118\n",
            "Epoch 220: GAIL Loss 0.333, Disc Loss 1.073\n",
            "Epoch 230: GAIL Loss 0.362, Disc Loss 1.080\n",
            "Epoch 240: GAIL Loss 0.330, Disc Loss 1.064\n",
            "Epoch 250: GAIL Loss 0.366, Disc Loss 1.110\n",
            "Epoch 260: GAIL Loss 0.348, Disc Loss 1.060\n",
            "Epoch 270: GAIL Loss 0.335, Disc Loss 1.083\n",
            "Epoch 280: GAIL Loss 0.364, Disc Loss 1.115\n",
            "Epoch 290: GAIL Loss 0.308, Disc Loss 0.983\n",
            "Epoch 300: GAIL Loss 0.313, Disc Loss 1.005\n",
            "Epoch 310: GAIL Loss 0.304, Disc Loss 1.031\n",
            "Epoch 320: GAIL Loss 0.283, Disc Loss 0.948\n",
            "Epoch 330: GAIL Loss 0.291, Disc Loss 0.923\n",
            "Epoch 340: GAIL Loss 0.304, Disc Loss 0.990\n",
            "Epoch 350: GAIL Loss 0.345, Disc Loss 1.072\n",
            "Epoch 360: GAIL Loss 0.289, Disc Loss 0.908\n",
            "Epoch 370: GAIL Loss 0.300, Disc Loss 0.926\n",
            "Epoch 380: GAIL Loss 0.247, Disc Loss 0.885\n",
            "Epoch 390: GAIL Loss 0.238, Disc Loss 0.794\n",
            "Epoch 400: GAIL Loss 0.251, Disc Loss 0.956\n",
            "Epoch 410: GAIL Loss 0.232, Disc Loss 0.862\n",
            "Epoch 420: GAIL Loss 0.223, Disc Loss 0.908\n",
            "Epoch 430: GAIL Loss 0.272, Disc Loss 0.848\n",
            "Epoch 440: GAIL Loss 0.393, Disc Loss 1.132\n",
            "Epoch 450: GAIL Loss 0.259, Disc Loss 0.895\n",
            "Epoch 460: GAIL Loss 0.344, Disc Loss 1.028\n",
            "Epoch 470: GAIL Loss 0.230, Disc Loss 0.847\n",
            "Epoch 480: GAIL Loss 0.492, Disc Loss 1.313\n",
            "Epoch 490: GAIL Loss 0.238, Disc Loss 0.830\n",
            "Epoch 500: GAIL Loss 0.245, Disc Loss 0.852\n",
            "Epoch 510: GAIL Loss 0.284, Disc Loss 0.901\n",
            "Epoch 520: GAIL Loss 0.229, Disc Loss 0.854\n",
            "Epoch 530: GAIL Loss 0.305, Disc Loss 0.924\n",
            "Epoch 540: GAIL Loss 0.314, Disc Loss 0.961\n",
            "Epoch 550: GAIL Loss 0.369, Disc Loss 1.023\n",
            "Epoch 560: GAIL Loss 0.207, Disc Loss 0.854\n",
            "Epoch 570: GAIL Loss 0.286, Disc Loss 0.847\n",
            "Epoch 580: GAIL Loss 0.195, Disc Loss 0.829\n",
            "Epoch 590: GAIL Loss 0.264, Disc Loss 0.835\n",
            "Epoch 600: GAIL Loss 0.209, Disc Loss 0.828\n",
            "Epoch 610: GAIL Loss 0.400, Disc Loss 1.104\n",
            "Epoch 620: GAIL Loss 0.240, Disc Loss 0.814\n",
            "Epoch 630: GAIL Loss 0.273, Disc Loss 0.853\n",
            "Epoch 640: GAIL Loss 0.275, Disc Loss 0.890\n",
            "Epoch 650: GAIL Loss 0.433, Disc Loss 1.158\n",
            "Epoch 660: GAIL Loss 0.204, Disc Loss 0.830\n",
            "Epoch 670: GAIL Loss 0.350, Disc Loss 1.020\n",
            "Epoch 680: GAIL Loss 0.269, Disc Loss 0.910\n",
            "Epoch 690: GAIL Loss 0.174, Disc Loss 0.728\n",
            "Epoch 700: GAIL Loss 0.205, Disc Loss 0.740\n",
            "Epoch 710: GAIL Loss 0.212, Disc Loss 0.898\n",
            "Epoch 720: GAIL Loss 0.209, Disc Loss 0.871\n",
            "Epoch 730: GAIL Loss 0.214, Disc Loss 0.808\n",
            "Epoch 740: GAIL Loss 0.349, Disc Loss 0.978\n",
            "Epoch 750: GAIL Loss 0.184, Disc Loss 0.747\n",
            "Epoch 760: GAIL Loss 0.185, Disc Loss 0.755\n",
            "Epoch 770: GAIL Loss 0.392, Disc Loss 1.097\n",
            "Epoch 780: GAIL Loss 0.228, Disc Loss 0.791\n",
            "Epoch 790: GAIL Loss 0.233, Disc Loss 0.798\n",
            "Epoch 800: GAIL Loss 0.219, Disc Loss 0.866\n",
            "Epoch 810: GAIL Loss 0.217, Disc Loss 0.810\n",
            "Epoch 820: GAIL Loss 0.307, Disc Loss 0.967\n",
            "Epoch 830: GAIL Loss 0.237, Disc Loss 0.781\n",
            "Epoch 840: GAIL Loss 0.175, Disc Loss 0.761\n",
            "Epoch 850: GAIL Loss 0.283, Disc Loss 0.861\n",
            "Epoch 860: GAIL Loss 0.205, Disc Loss 0.681\n",
            "Epoch 870: GAIL Loss 0.242, Disc Loss 0.890\n",
            "Epoch 880: GAIL Loss 0.201, Disc Loss 0.739\n",
            "Epoch 890: GAIL Loss 0.205, Disc Loss 0.842\n",
            "Epoch 900: GAIL Loss 0.265, Disc Loss 0.887\n",
            "Epoch 910: GAIL Loss 0.236, Disc Loss 0.853\n",
            "Epoch 920: GAIL Loss 0.181, Disc Loss 0.729\n",
            "Epoch 930: GAIL Loss 0.230, Disc Loss 0.845\n",
            "Epoch 940: GAIL Loss 0.311, Disc Loss 0.907\n",
            "Epoch 950: GAIL Loss 0.235, Disc Loss 0.817\n",
            "Epoch 960: GAIL Loss 0.173, Disc Loss 0.714\n",
            "Epoch 970: GAIL Loss 0.144, Disc Loss 0.710\n",
            "Epoch 980: GAIL Loss 0.217, Disc Loss 0.773\n",
            "Epoch 990: GAIL Loss 0.218, Disc Loss 0.744\n",
            "Epoch 1000: GAIL Loss 0.203, Disc Loss 0.784\n",
            "Epoch 1010: GAIL Loss 0.202, Disc Loss 0.693\n",
            "Epoch 1020: GAIL Loss 0.177, Disc Loss 0.855\n",
            "Epoch 1030: GAIL Loss 0.240, Disc Loss 0.767\n",
            "Epoch 1040: GAIL Loss 0.339, Disc Loss 0.922\n",
            "Epoch 1050: GAIL Loss 0.256, Disc Loss 0.834\n",
            "Epoch 1060: GAIL Loss 0.221, Disc Loss 0.878\n",
            "Epoch 1070: GAIL Loss 0.201, Disc Loss 0.746\n",
            "Epoch 1080: GAIL Loss 0.275, Disc Loss 0.912\n",
            "Epoch 1090: GAIL Loss 0.213, Disc Loss 0.879\n",
            "Epoch 1100: GAIL Loss 0.252, Disc Loss 0.931\n",
            "Epoch 1110: GAIL Loss 0.203, Disc Loss 0.747\n",
            "Epoch 1120: GAIL Loss 0.213, Disc Loss 0.777\n",
            "Epoch 1130: GAIL Loss 0.318, Disc Loss 0.979\n",
            "Epoch 1140: GAIL Loss 0.177, Disc Loss 0.760\n",
            "Epoch 1150: GAIL Loss 0.157, Disc Loss 0.796\n",
            "Epoch 1160: GAIL Loss 0.199, Disc Loss 0.761\n",
            "Epoch 1170: GAIL Loss 0.199, Disc Loss 0.688\n",
            "Epoch 1180: GAIL Loss 0.151, Disc Loss 0.656\n",
            "Epoch 1190: GAIL Loss 0.243, Disc Loss 0.831\n",
            "Epoch 1200: GAIL Loss 0.201, Disc Loss 0.772\n",
            "Epoch 1210: GAIL Loss 0.254, Disc Loss 1.032\n",
            "Epoch 1220: GAIL Loss 0.182, Disc Loss 0.696\n",
            "Epoch 1230: GAIL Loss 0.195, Disc Loss 0.703\n",
            "Epoch 1240: GAIL Loss 0.190, Disc Loss 0.754\n",
            "Epoch 1250: GAIL Loss 0.184, Disc Loss 0.669\n",
            "Epoch 1260: GAIL Loss 0.130, Disc Loss 0.770\n",
            "Epoch 1270: GAIL Loss 0.238, Disc Loss 0.779\n",
            "Epoch 1280: GAIL Loss 0.202, Disc Loss 0.831\n",
            "Epoch 1290: GAIL Loss 0.186, Disc Loss 0.604\n",
            "Epoch 1300: GAIL Loss 0.146, Disc Loss 0.780\n",
            "Epoch 1310: GAIL Loss 0.315, Disc Loss 1.026\n",
            "Epoch 1320: GAIL Loss 0.235, Disc Loss 0.931\n",
            "Epoch 1330: GAIL Loss 0.130, Disc Loss 0.665\n",
            "Epoch 1340: GAIL Loss 0.193, Disc Loss 0.745\n",
            "Epoch 1350: GAIL Loss 0.218, Disc Loss 0.853\n",
            "Epoch 1360: GAIL Loss 0.205, Disc Loss 0.690\n",
            "Epoch 1370: GAIL Loss 0.280, Disc Loss 0.955\n",
            "Epoch 1380: GAIL Loss 0.160, Disc Loss 0.767\n",
            "Epoch 1390: GAIL Loss 0.178, Disc Loss 0.855\n",
            "Epoch 1400: GAIL Loss 0.314, Disc Loss 1.156\n",
            "Epoch 1410: GAIL Loss 0.193, Disc Loss 0.789\n",
            "Epoch 1420: GAIL Loss 0.196, Disc Loss 0.765\n",
            "Epoch 1430: GAIL Loss 0.197, Disc Loss 0.734\n",
            "Epoch 1440: GAIL Loss 0.315, Disc Loss 1.491\n",
            "Epoch 1450: GAIL Loss 0.231, Disc Loss 0.836\n",
            "Epoch 1460: GAIL Loss 0.181, Disc Loss 0.740\n",
            "Epoch 1470: GAIL Loss 0.160, Disc Loss 0.657\n",
            "Epoch 1480: GAIL Loss 0.178, Disc Loss 0.713\n",
            "Epoch 1490: GAIL Loss 0.171, Disc Loss 0.828\n",
            "Epoch 1500: GAIL Loss 0.158, Disc Loss 0.703\n",
            "Epoch 1510: GAIL Loss 0.202, Disc Loss 0.943\n",
            "Epoch 1520: GAIL Loss 0.210, Disc Loss 0.748\n",
            "Epoch 1530: GAIL Loss 0.195, Disc Loss 0.897\n",
            "Epoch 1540: GAIL Loss 0.174, Disc Loss 0.634\n",
            "Epoch 1550: GAIL Loss 0.164, Disc Loss 0.737\n",
            "Epoch 1560: GAIL Loss 0.171, Disc Loss 0.831\n",
            "Epoch 1570: GAIL Loss 0.215, Disc Loss 0.845\n",
            "Epoch 1580: GAIL Loss 0.293, Disc Loss 1.129\n",
            "Epoch 1590: GAIL Loss 0.166, Disc Loss 0.774\n",
            "Epoch 1600: GAIL Loss 0.193, Disc Loss 0.809\n",
            "Epoch 1610: GAIL Loss 0.206, Disc Loss 0.890\n",
            "Epoch 1620: GAIL Loss 0.173, Disc Loss 0.732\n",
            "Epoch 1630: GAIL Loss 0.140, Disc Loss 0.840\n",
            "Epoch 1640: GAIL Loss 0.172, Disc Loss 0.688\n",
            "Epoch 1650: GAIL Loss 0.167, Disc Loss 0.632\n",
            "Epoch 1660: GAIL Loss 0.141, Disc Loss 0.664\n",
            "Epoch 1670: GAIL Loss 0.128, Disc Loss 0.625\n",
            "Epoch 1680: GAIL Loss 0.148, Disc Loss 0.587\n",
            "Epoch 1690: GAIL Loss 0.146, Disc Loss 0.654\n",
            "Epoch 1700: GAIL Loss 0.162, Disc Loss 0.718\n",
            "Epoch 1710: GAIL Loss 0.109, Disc Loss 0.671\n",
            "Epoch 1720: GAIL Loss 0.162, Disc Loss 0.707\n",
            "Epoch 1730: GAIL Loss 0.239, Disc Loss 0.923\n",
            "Epoch 1740: GAIL Loss 0.131, Disc Loss 0.739\n",
            "Epoch 1750: GAIL Loss 0.265, Disc Loss 1.039\n",
            "Epoch 1760: GAIL Loss 0.221, Disc Loss 0.914\n",
            "Epoch 1770: GAIL Loss 0.185, Disc Loss 0.824\n",
            "Epoch 1780: GAIL Loss 0.147, Disc Loss 0.669\n",
            "Epoch 1790: GAIL Loss 0.151, Disc Loss 0.746\n",
            "Epoch 1800: GAIL Loss 0.271, Disc Loss 1.361\n",
            "Epoch 1810: GAIL Loss 0.317, Disc Loss 1.062\n",
            "Epoch 1820: GAIL Loss 0.166, Disc Loss 0.684\n",
            "Epoch 1830: GAIL Loss 0.144, Disc Loss 0.728\n",
            "Epoch 1840: GAIL Loss 0.138, Disc Loss 0.801\n",
            "Epoch 1850: GAIL Loss 0.223, Disc Loss 0.857\n",
            "Epoch 1860: GAIL Loss 0.180, Disc Loss 0.789\n",
            "Epoch 1870: GAIL Loss 0.162, Disc Loss 0.674\n",
            "Epoch 1880: GAIL Loss 0.187, Disc Loss 0.861\n",
            "Epoch 1890: GAIL Loss 0.146, Disc Loss 0.720\n",
            "Epoch 1900: GAIL Loss 0.143, Disc Loss 0.697\n",
            "Epoch 1910: GAIL Loss 0.153, Disc Loss 0.648\n",
            "Epoch 1920: GAIL Loss 0.175, Disc Loss 0.857\n",
            "Epoch 1930: GAIL Loss 0.140, Disc Loss 0.638\n",
            "Epoch 1940: GAIL Loss 0.135, Disc Loss 0.705\n",
            "Epoch 1950: GAIL Loss 0.157, Disc Loss 0.682\n",
            "Epoch 1960: GAIL Loss 0.294, Disc Loss 1.011\n",
            "Epoch 1970: GAIL Loss 0.182, Disc Loss 0.805\n",
            "Epoch 1980: GAIL Loss 0.143, Disc Loss 0.654\n",
            "Epoch 1990: GAIL Loss 0.128, Disc Loss 0.739\n",
            "Epoch 2000: GAIL Loss 0.194, Disc Loss 0.775\n",
            "Epoch 2010: GAIL Loss 0.158, Disc Loss 0.830\n",
            "Epoch 2020: GAIL Loss 0.160, Disc Loss 0.710\n",
            "Epoch 2030: GAIL Loss 0.122, Disc Loss 0.784\n",
            "Epoch 2040: GAIL Loss 0.181, Disc Loss 0.834\n",
            "Epoch 2050: GAIL Loss 0.195, Disc Loss 0.817\n",
            "Epoch 2060: GAIL Loss 0.115, Disc Loss 0.642\n",
            "Epoch 2070: GAIL Loss 0.130, Disc Loss 0.712\n",
            "Epoch 2080: GAIL Loss 0.354, Disc Loss 1.046\n",
            "Epoch 2090: GAIL Loss 0.135, Disc Loss 0.726\n",
            "Epoch 2100: GAIL Loss 0.182, Disc Loss 0.761\n",
            "Epoch 2110: GAIL Loss 0.138, Disc Loss 0.642\n",
            "Epoch 2120: GAIL Loss 0.120, Disc Loss 0.708\n",
            "Epoch 2130: GAIL Loss 0.119, Disc Loss 0.793\n",
            "Epoch 2140: GAIL Loss 0.181, Disc Loss 0.872\n",
            "Epoch 2150: GAIL Loss 0.386, Disc Loss 1.538\n",
            "Epoch 2160: GAIL Loss 0.123, Disc Loss 0.841\n",
            "Epoch 2170: GAIL Loss 0.245, Disc Loss 0.858\n",
            "Epoch 2180: GAIL Loss 0.152, Disc Loss 0.686\n",
            "Epoch 2190: GAIL Loss 0.146, Disc Loss 0.849\n",
            "Epoch 2200: GAIL Loss 0.108, Disc Loss 0.724\n",
            "Epoch 2210: GAIL Loss 0.130, Disc Loss 0.661\n",
            "Epoch 2220: GAIL Loss 0.143, Disc Loss 0.712\n",
            "Epoch 2230: GAIL Loss 0.334, Disc Loss 1.117\n",
            "Epoch 2240: GAIL Loss 0.180, Disc Loss 0.715\n",
            "Epoch 2250: GAIL Loss 0.138, Disc Loss 0.736\n",
            "Epoch 2260: GAIL Loss 0.318, Disc Loss 1.252\n",
            "Epoch 2270: GAIL Loss 0.230, Disc Loss 1.052\n",
            "Epoch 2280: GAIL Loss 0.173, Disc Loss 0.686\n",
            "Epoch 2290: GAIL Loss 0.172, Disc Loss 0.802\n",
            "Epoch 2300: GAIL Loss 0.141, Disc Loss 0.774\n",
            "Epoch 2310: GAIL Loss 0.085, Disc Loss 0.750\n",
            "Epoch 2320: GAIL Loss 0.181, Disc Loss 0.907\n",
            "Epoch 2330: GAIL Loss 0.157, Disc Loss 0.685\n",
            "Epoch 2340: GAIL Loss 0.113, Disc Loss 0.713\n",
            "Epoch 2350: GAIL Loss 0.122, Disc Loss 0.674\n",
            "Epoch 2360: GAIL Loss 0.172, Disc Loss 0.711\n",
            "Epoch 2370: GAIL Loss 0.114, Disc Loss 0.748\n",
            "Epoch 2380: GAIL Loss 0.109, Disc Loss 0.685\n",
            "Epoch 2390: GAIL Loss 0.122, Disc Loss 0.660\n",
            "Epoch 2400: GAIL Loss 0.154, Disc Loss 0.714\n",
            "Epoch 2410: GAIL Loss 0.226, Disc Loss 0.771\n",
            "Epoch 2420: GAIL Loss 0.143, Disc Loss 0.742\n",
            "Epoch 2430: GAIL Loss 0.162, Disc Loss 0.807\n",
            "Epoch 2440: GAIL Loss 0.104, Disc Loss 0.656\n",
            "Epoch 2450: GAIL Loss 0.140, Disc Loss 0.817\n",
            "Epoch 2460: GAIL Loss 0.118, Disc Loss 0.742\n",
            "Epoch 2470: GAIL Loss 0.101, Disc Loss 0.683\n",
            "Epoch 2480: GAIL Loss 0.095, Disc Loss 0.779\n",
            "Epoch 2490: GAIL Loss 0.109, Disc Loss 0.666\n",
            "Epoch 2500: GAIL Loss 0.149, Disc Loss 0.721\n",
            "Epoch 2510: GAIL Loss 0.094, Disc Loss 0.698\n",
            "Epoch 2520: GAIL Loss 0.216, Disc Loss 0.887\n",
            "Epoch 2530: GAIL Loss 0.141, Disc Loss 0.730\n",
            "Epoch 2540: GAIL Loss 0.111, Disc Loss 0.684\n",
            "Epoch 2550: GAIL Loss 0.094, Disc Loss 0.698\n",
            "Epoch 2560: GAIL Loss 0.124, Disc Loss 0.726\n",
            "Epoch 2570: GAIL Loss 0.108, Disc Loss 0.814\n",
            "Epoch 2580: GAIL Loss 0.215, Disc Loss 1.147\n",
            "Epoch 2590: GAIL Loss 0.173, Disc Loss 1.067\n",
            "Epoch 2600: GAIL Loss 0.106, Disc Loss 0.777\n",
            "Epoch 2610: GAIL Loss 0.116, Disc Loss 0.790\n",
            "Epoch 2620: GAIL Loss 0.140, Disc Loss 0.860\n",
            "Epoch 2630: GAIL Loss 0.143, Disc Loss 1.012\n",
            "Epoch 2640: GAIL Loss 0.115, Disc Loss 0.794\n",
            "Epoch 2650: GAIL Loss 0.324, Disc Loss 1.471\n",
            "Epoch 2660: GAIL Loss 0.266, Disc Loss 1.385\n",
            "Epoch 2670: GAIL Loss 0.201, Disc Loss 0.977\n",
            "Epoch 2680: GAIL Loss 0.190, Disc Loss 0.944\n",
            "Epoch 2690: GAIL Loss 0.119, Disc Loss 0.817\n",
            "Epoch 2700: GAIL Loss 0.123, Disc Loss 0.951\n",
            "Epoch 2710: GAIL Loss 0.184, Disc Loss 0.923\n",
            "Epoch 2720: GAIL Loss 0.128, Disc Loss 0.846\n",
            "Epoch 2730: GAIL Loss 0.219, Disc Loss 1.051\n",
            "Epoch 2740: GAIL Loss 0.204, Disc Loss 0.991\n",
            "Epoch 2750: GAIL Loss 0.123, Disc Loss 1.061\n",
            "Epoch 2760: GAIL Loss 0.148, Disc Loss 1.206\n",
            "Epoch 2770: GAIL Loss 0.123, Disc Loss 0.854\n",
            "Epoch 2780: GAIL Loss 0.211, Disc Loss 1.201\n",
            "Epoch 2790: GAIL Loss 0.104, Disc Loss 0.903\n",
            "Epoch 2800: GAIL Loss 0.127, Disc Loss 0.965\n",
            "Epoch 2810: GAIL Loss 0.154, Disc Loss 0.924\n",
            "Epoch 2820: GAIL Loss 0.237, Disc Loss 1.161\n",
            "Epoch 2830: GAIL Loss 0.198, Disc Loss 1.301\n",
            "Epoch 2840: GAIL Loss 0.167, Disc Loss 1.199\n",
            "Epoch 2850: GAIL Loss 0.153, Disc Loss 1.313\n",
            "Epoch 2860: GAIL Loss 0.175, Disc Loss 1.350\n",
            "Epoch 2870: GAIL Loss 0.171, Disc Loss 1.211\n",
            "Epoch 2880: GAIL Loss 0.136, Disc Loss 0.888\n",
            "Epoch 2890: GAIL Loss 0.191, Disc Loss 1.288\n",
            "Epoch 2900: GAIL Loss 0.124, Disc Loss 0.894\n",
            "Epoch 2910: GAIL Loss 0.182, Disc Loss 1.396\n",
            "Epoch 2920: GAIL Loss 0.205, Disc Loss 1.074\n",
            "Epoch 2930: GAIL Loss 0.140, Disc Loss 0.962\n",
            "Epoch 2940: GAIL Loss 0.170, Disc Loss 1.479\n",
            "Epoch 2950: GAIL Loss 0.139, Disc Loss 1.109\n",
            "Epoch 2960: GAIL Loss 0.162, Disc Loss 1.273\n",
            "Epoch 2970: GAIL Loss 0.175, Disc Loss 1.559\n",
            "Epoch 2980: GAIL Loss 0.150, Disc Loss 1.507\n",
            "Epoch 2990: GAIL Loss 0.156, Disc Loss 1.497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Протестируйте ваш алгоритм"
      ],
      "metadata": {
        "id": "LDR6MRslIvL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for episode in range(10):\n",
        "    obs, _ = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    t = 0\n",
        "\n",
        "    while not done:\n",
        "        obs_with_time = np.append(obs, [np.sin(t), np.cos(t)])\n",
        "        obs_tensor = torch.tensor(obs_with_time, dtype=torch.float32).unsqueeze(0)\n",
        "        action = policy.get_action(obs_tensor)\n",
        "        next_obs, reward, terminated, truncated, _ = env.step(action)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        obs = next_obs\n",
        "        total_reward += reward\n",
        "        t += 1\n",
        "    print(total_reward)\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNb5HTBPFTOM",
        "outputId": "09456be0-c34b-4229-8bcf-4beb78c83696"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-190.0\n",
            "-163.0\n",
            "-200.0\n",
            "-198.0\n",
            "-132.0\n",
            "-164.0\n",
            "-194.0\n",
            "-136.0\n",
            "-200.0\n",
            "-200.0\n"
          ]
        }
      ]
    }
  ]
}