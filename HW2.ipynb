{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Реализуйте алгоритм SAC для среды lunar lander"
      ],
      "metadata": {
        "id": "Sr7dwOCeR0oU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install swig\n",
        "!pip install \"gymnasium[box2d]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjQrXMAXg702",
        "outputId": "7a21aaf0-3e28-481c-89dc-25a792b6c453"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting swig\n",
            "  Downloading swig-4.3.1-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (3.5 kB)\n",
            "Downloading swig-4.3.1-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.3.1\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (4.13.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (2.6.1)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (4.3.1)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp311-cp311-linux_x86_64.whl size=2379369 sha256=ad175533295272e3ecf80cdd6d9a363c5de9f3c08d1f54da803a76171db1a0c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/f1/0c/d56f4a2bdd12bae0a0693ec33f2f0daadb5eb9753c78fa5308\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from collections import deque\n",
        "import random\n",
        "from torch.distributions import Normal"
      ],
      "metadata": {
        "id": "MN6a51jLg8Ge"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GAMMA = 0.99\n",
        "TAU = 0.005\n",
        "ALPHA = 0.2\n",
        "ACTOR_LR = 3e-4\n",
        "CRITIC_LR = 3e-4\n",
        "REPLAY_SIZE = 100000\n",
        "BATCH_SIZE = 256\n",
        "START_STEPS = 10000\n",
        "TOTAL_STEPS = 200000\n",
        "UPDATE_AFTER = 1000\n",
        "UPDATE_EVERY = 50\n",
        "\n",
        "EPISODE_WINDOW = 100\n",
        "TARGET_AVG_RETURN = 200"
      ],
      "metadata": {
        "id": "OrmQtoBmg-Cu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "tfzBEkl4h3Lv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Actor(nn.Module):\n",
        "    def __init__(self, obs_dim, act_dim, action_low, action_high):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(obs_dim, 256), nn.ReLU(),\n",
        "            nn.Linear(256, 256), nn.ReLU()\n",
        "        )\n",
        "        self.mu_layer = nn.Linear(256, act_dim)\n",
        "        self.log_std_layer = nn.Linear(256, act_dim)\n",
        "        self.action_low = torch.tensor(action_low, device=device)\n",
        "        self.action_high = torch.tensor(action_high, device=device)\n",
        "\n",
        "    def forward(self, obs):\n",
        "        x = self.net(obs)\n",
        "        mean = self.mu_layer(x)\n",
        "        log_std = self.log_std_layer(x)\n",
        "        log_std = torch.clamp(log_std, -20, 2)\n",
        "        std = log_std.exp()\n",
        "\n",
        "        normal = Normal(mean, std)\n",
        "        x_t = normal.rsample()\n",
        "        y_t = torch.tanh(x_t)\n",
        "        action = y_t * (self.action_high - self.action_low)/2 + (self.action_high + self.action_low)/2\n",
        "\n",
        "        log_prob = normal.log_prob(x_t)\n",
        "        log_prob -= torch.log((1 - y_t.pow(2)) + 1e-6)\n",
        "        log_prob = log_prob.sum(1, keepdim=True)\n",
        "\n",
        "        return action, log_prob\n",
        "\n",
        "    def get_action(self, obs, deterministic=False):\n",
        "        with torch.no_grad():\n",
        "            obs_tensor = torch.FloatTensor(obs).to(device).unsqueeze(0)\n",
        "            x = self.net(obs_tensor)\n",
        "            mean = self.mu_layer(x)\n",
        "            if deterministic:\n",
        "                action = torch.tanh(mean)\n",
        "            else:\n",
        "                log_std = self.log_std_layer(x)\n",
        "                log_std = torch.clamp(log_std, -20, 2)\n",
        "                std = log_std.exp()\n",
        "                normal = Normal(mean, std)\n",
        "                x_t = normal.rsample()\n",
        "                action = torch.tanh(x_t)\n",
        "            action = action * (self.action_high - self.action_low)/2 + (self.action_high + self.action_low)/2\n",
        "            return action.squeeze().cpu().numpy()"
      ],
      "metadata": {
        "id": "iPYOjK6Gg_tW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Critic(nn.Module):\n",
        "    def __init__(self, obs_dim, act_dim):\n",
        "        super().__init__()\n",
        "        self.q1 = nn.Sequential(\n",
        "            nn.Linear(obs_dim + act_dim, 256), nn.ReLU(),\n",
        "            nn.Linear(256, 256), nn.ReLU(),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "        self.q2 = nn.Sequential(\n",
        "            nn.Linear(obs_dim + act_dim, 256), nn.ReLU(),\n",
        "            nn.Linear(256, 256), nn.ReLU(),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, obs, act):\n",
        "        x = torch.cat([obs, act], dim=-1)\n",
        "        return self.q1(x), self.q2(x)"
      ],
      "metadata": {
        "id": "A0jBQNi1hBJ2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer:\n",
        "    def __init__(self, size):\n",
        "        self.buffer = deque(maxlen=size)\n",
        "\n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        self.buffer.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        batch = random.sample(self.buffer, batch_size)\n",
        "        states, actions, rewards, next_states, dones = zip(*batch)\n",
        "        return (\n",
        "            torch.FloatTensor(np.array(states)).to(device),\n",
        "            torch.FloatTensor(np.array(actions)).to(device),\n",
        "            torch.FloatTensor(np.array(rewards)).unsqueeze(1).to(device),\n",
        "            torch.FloatTensor(np.array(next_states)).to(device),\n",
        "            torch.FloatTensor(np.array(dones)).unsqueeze(1).to(device)\n",
        "        )"
      ],
      "metadata": {
        "id": "8Q1PTqcNhGhG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"LunarLanderContinuous-v3\")\n",
        "obs_dim = env.observation_space.shape[0]\n",
        "act_dim = env.action_space.shape[0]\n",
        "action_low = env.action_space.low[0]\n",
        "action_high = env.action_space.high[0]\n",
        "\n",
        "actor = Actor(obs_dim, act_dim, action_low, action_high).to(device)\n",
        "critic = Critic(obs_dim, act_dim).to(device)\n",
        "critic_target = Critic(obs_dim, act_dim).to(device)\n",
        "critic_target.load_state_dict(critic.state_dict())\n",
        "\n",
        "actor_optim = optim.Adam(actor.parameters(), lr=ACTOR_LR)\n",
        "critic_optim = optim.Adam(critic.parameters(), lr=CRITIC_LR)\n",
        "\n",
        "replay_buffer = ReplayBuffer(REPLAY_SIZE)"
      ],
      "metadata": {
        "id": "RGQmmzSohIS2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update():\n",
        "    states, actions, rewards, next_states, dones = replay_buffer.sample(BATCH_SIZE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        next_actions, log_probs = actor(next_states)\n",
        "        target_q1, target_q2 = critic_target(next_states, next_actions)\n",
        "        target_q = torch.min(target_q1, target_q2) - ALPHA * log_probs\n",
        "        target_q = rewards + GAMMA * (1 - dones) * target_q\n",
        "\n",
        "    current_q1, current_q2 = critic(states, actions)\n",
        "    critic_loss = F.mse_loss(current_q1, target_q) + F.mse_loss(current_q2, target_q)\n",
        "\n",
        "    critic_optim.zero_grad()\n",
        "    critic_loss.backward()\n",
        "    critic_optim.step()\n",
        "\n",
        "    for param in critic.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    actions_pred, log_probs_pred = actor(states)\n",
        "    q1_pred, q2_pred = critic(states, actions_pred)\n",
        "    actor_loss = (ALPHA * log_probs_pred - torch.min(q1_pred, q2_pred)).mean()\n",
        "\n",
        "    actor_optim.zero_grad()\n",
        "    actor_loss.backward()\n",
        "    actor_optim.step()\n",
        "\n",
        "    for param in critic.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for param, target_param in zip(critic.parameters(), critic_target.parameters()):\n",
        "            target_param.data.copy_(TAU * param.data + (1 - TAU) * target_param.data)\n",
        "\n",
        "obs, _ = env.reset()\n",
        "episode_return = 0\n",
        "episode_length = 0"
      ],
      "metadata": {
        "id": "qyTQEqzshJou"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "episode_history = deque(maxlen=EPISODE_WINDOW)\n",
        "episode_counter = 0\n",
        "\n",
        "for step in range(1, TOTAL_STEPS + 1):\n",
        "    if step <= START_STEPS:\n",
        "        action = env.action_space.sample()\n",
        "    else:\n",
        "        action = actor.get_action(obs)\n",
        "\n",
        "    next_obs, reward, terminated, truncated, _ = env.step(action)\n",
        "    done = terminated or truncated\n",
        "    replay_buffer.add(obs, action, reward, next_obs, done)\n",
        "\n",
        "    obs = next_obs\n",
        "    episode_return += reward\n",
        "    episode_length += 1\n",
        "\n",
        "    if done:\n",
        "        # Добавляем результат эпизода в историю\n",
        "        episode_history.append(episode_return)\n",
        "        episode_counter += 1\n",
        "\n",
        "        print(f\"Episode: {episode_counter}\")\n",
        "\n",
        "        # Выводим статистику\n",
        "        print(f\"Step: {step}, Return: {episode_return:.2f}, Length: {episode_length}\")\n",
        "\n",
        "        # Рассчитываем и выводим среднее каждые 100 эпизодов\n",
        "        if episode_counter % EPISODE_WINDOW == 0:\n",
        "            avg_return = np.mean(episode_history)\n",
        "            print(f\"\\n--- Средний возврат за последние {EPISODE_WINDOW} эпизодов: {avg_return:.2f} ---\\n\")\n",
        "\n",
        "            # Проверяем условие ранней остановки\n",
        "            if avg_return >= TARGET_AVG_RETURN:\n",
        "                print(f\"Обучение остановлено! Достигнут средний возврат {avg_return:.2f} за {EPISODE_WINDOW} эпизодов\")\n",
        "                break\n",
        "\n",
        "        # Сброс для нового эпизода\n",
        "        obs, _ = env.reset()\n",
        "        episode_return = 0\n",
        "        episode_length = 0\n",
        "\n",
        "    if step >= UPDATE_AFTER and step % UPDATE_EVERY == 0:\n",
        "        for _ in range(UPDATE_EVERY):\n",
        "            update()\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcoXVAlphLVn",
        "outputId": "9984ad26-89f4-4744-92f0-38d266ebe6bc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 1\n",
            "Step: 135, Return: -310.41, Length: 135\n",
            "Episode: 2\n",
            "Step: 222, Return: -375.83, Length: 87\n",
            "Episode: 3\n",
            "Step: 300, Return: -43.98, Length: 78\n",
            "Episode: 4\n",
            "Step: 464, Return: -442.25, Length: 164\n",
            "Episode: 5\n",
            "Step: 580, Return: -326.35, Length: 116\n",
            "Episode: 6\n",
            "Step: 693, Return: -300.06, Length: 113\n",
            "Episode: 7\n",
            "Step: 790, Return: -70.06, Length: 97\n",
            "Episode: 8\n",
            "Step: 908, Return: -72.75, Length: 118\n",
            "Episode: 9\n",
            "Step: 1016, Return: -183.87, Length: 108\n",
            "Episode: 10\n",
            "Step: 1097, Return: -145.50, Length: 81\n",
            "Episode: 11\n",
            "Step: 1174, Return: -438.46, Length: 77\n",
            "Episode: 12\n",
            "Step: 1278, Return: -332.20, Length: 104\n",
            "Episode: 13\n",
            "Step: 1370, Return: -306.59, Length: 92\n",
            "Episode: 14\n",
            "Step: 1435, Return: -240.44, Length: 65\n",
            "Episode: 15\n",
            "Step: 1526, Return: -166.52, Length: 91\n",
            "Episode: 16\n",
            "Step: 1661, Return: -251.95, Length: 135\n",
            "Episode: 17\n",
            "Step: 1786, Return: -71.45, Length: 125\n",
            "Episode: 18\n",
            "Step: 1886, Return: -52.88, Length: 100\n",
            "Episode: 19\n",
            "Step: 1996, Return: -90.99, Length: 110\n",
            "Episode: 20\n",
            "Step: 2119, Return: -96.01, Length: 123\n",
            "Episode: 21\n",
            "Step: 2222, Return: -269.31, Length: 103\n",
            "Episode: 22\n",
            "Step: 2317, Return: -154.80, Length: 95\n",
            "Episode: 23\n",
            "Step: 2399, Return: -364.62, Length: 82\n",
            "Episode: 24\n",
            "Step: 2523, Return: -488.02, Length: 124\n",
            "Episode: 25\n",
            "Step: 2589, Return: -119.94, Length: 66\n",
            "Episode: 26\n",
            "Step: 2721, Return: -290.49, Length: 132\n",
            "Episode: 27\n",
            "Step: 2901, Return: -276.37, Length: 180\n",
            "Episode: 28\n",
            "Step: 3025, Return: -229.97, Length: 124\n",
            "Episode: 29\n",
            "Step: 3132, Return: -224.48, Length: 107\n",
            "Episode: 30\n",
            "Step: 3228, Return: -149.44, Length: 96\n",
            "Episode: 31\n",
            "Step: 3333, Return: -309.92, Length: 105\n",
            "Episode: 32\n",
            "Step: 3466, Return: -178.54, Length: 133\n",
            "Episode: 33\n",
            "Step: 3574, Return: -231.97, Length: 108\n",
            "Episode: 34\n",
            "Step: 3707, Return: -296.34, Length: 133\n",
            "Episode: 35\n",
            "Step: 3836, Return: -100.34, Length: 129\n",
            "Episode: 36\n",
            "Step: 3912, Return: -104.97, Length: 76\n",
            "Episode: 37\n",
            "Step: 3998, Return: -310.21, Length: 86\n",
            "Episode: 38\n",
            "Step: 4117, Return: -122.15, Length: 119\n",
            "Episode: 39\n",
            "Step: 4210, Return: -355.32, Length: 93\n",
            "Episode: 40\n",
            "Step: 4292, Return: -189.32, Length: 82\n",
            "Episode: 41\n",
            "Step: 4370, Return: -142.74, Length: 78\n",
            "Episode: 42\n",
            "Step: 4443, Return: -188.21, Length: 73\n",
            "Episode: 43\n",
            "Step: 4529, Return: -82.34, Length: 86\n",
            "Episode: 44\n",
            "Step: 4621, Return: -160.89, Length: 92\n",
            "Episode: 45\n",
            "Step: 4697, Return: -85.03, Length: 76\n",
            "Episode: 46\n",
            "Step: 4854, Return: -276.77, Length: 157\n",
            "Episode: 47\n",
            "Step: 4935, Return: -117.55, Length: 81\n",
            "Episode: 48\n",
            "Step: 5065, Return: -48.20, Length: 130\n",
            "Episode: 49\n",
            "Step: 5202, Return: -333.11, Length: 137\n",
            "Episode: 50\n",
            "Step: 5339, Return: -117.19, Length: 137\n",
            "Episode: 51\n",
            "Step: 5452, Return: -183.67, Length: 113\n",
            "Episode: 52\n",
            "Step: 5571, Return: -215.65, Length: 119\n",
            "Episode: 53\n",
            "Step: 5650, Return: -217.19, Length: 79\n",
            "Episode: 54\n",
            "Step: 5811, Return: -144.17, Length: 161\n",
            "Episode: 55\n",
            "Step: 5941, Return: -128.25, Length: 130\n",
            "Episode: 56\n",
            "Step: 6064, Return: -191.46, Length: 123\n",
            "Episode: 57\n",
            "Step: 6148, Return: -82.58, Length: 84\n",
            "Episode: 58\n",
            "Step: 6229, Return: -301.20, Length: 81\n",
            "Episode: 59\n",
            "Step: 6322, Return: -140.05, Length: 93\n",
            "Episode: 60\n",
            "Step: 6419, Return: -347.57, Length: 97\n",
            "Episode: 61\n",
            "Step: 6530, Return: -73.61, Length: 111\n",
            "Episode: 62\n",
            "Step: 6626, Return: -193.13, Length: 96\n",
            "Episode: 63\n",
            "Step: 6712, Return: -58.33, Length: 86\n",
            "Episode: 64\n",
            "Step: 6831, Return: -274.89, Length: 119\n",
            "Episode: 65\n",
            "Step: 6981, Return: -517.94, Length: 150\n",
            "Episode: 66\n",
            "Step: 7167, Return: -247.25, Length: 186\n",
            "Episode: 67\n",
            "Step: 7257, Return: -12.89, Length: 90\n",
            "Episode: 68\n",
            "Step: 7369, Return: -349.74, Length: 112\n",
            "Episode: 69\n",
            "Step: 7530, Return: -319.74, Length: 161\n",
            "Episode: 70\n",
            "Step: 7594, Return: -111.86, Length: 64\n",
            "Episode: 71\n",
            "Step: 7673, Return: -190.88, Length: 79\n",
            "Episode: 72\n",
            "Step: 7757, Return: -97.07, Length: 84\n",
            "Episode: 73\n",
            "Step: 7861, Return: -345.92, Length: 104\n",
            "Episode: 74\n",
            "Step: 7976, Return: -240.09, Length: 115\n",
            "Episode: 75\n",
            "Step: 8041, Return: -88.85, Length: 65\n",
            "Episode: 76\n",
            "Step: 8185, Return: -313.28, Length: 144\n",
            "Episode: 77\n",
            "Step: 8263, Return: -117.34, Length: 78\n",
            "Episode: 78\n",
            "Step: 8361, Return: -475.68, Length: 98\n",
            "Episode: 79\n",
            "Step: 8513, Return: -193.28, Length: 152\n",
            "Episode: 80\n",
            "Step: 8676, Return: -399.12, Length: 163\n",
            "Episode: 81\n",
            "Step: 8801, Return: -272.22, Length: 125\n",
            "Episode: 82\n",
            "Step: 8926, Return: -240.68, Length: 125\n",
            "Episode: 83\n",
            "Step: 9017, Return: -302.08, Length: 91\n",
            "Episode: 84\n",
            "Step: 9184, Return: -132.18, Length: 167\n",
            "Episode: 85\n",
            "Step: 9297, Return: -437.09, Length: 113\n",
            "Episode: 86\n",
            "Step: 9436, Return: -135.94, Length: 139\n",
            "Episode: 87\n",
            "Step: 9533, Return: -113.59, Length: 97\n",
            "Episode: 88\n",
            "Step: 9626, Return: -349.99, Length: 93\n",
            "Episode: 89\n",
            "Step: 9695, Return: -178.71, Length: 69\n",
            "Episode: 90\n",
            "Step: 9768, Return: -86.44, Length: 73\n",
            "Episode: 91\n",
            "Step: 9871, Return: -129.30, Length: 103\n",
            "Episode: 92\n",
            "Step: 9979, Return: -226.04, Length: 108\n",
            "Episode: 93\n",
            "Step: 10200, Return: -62.49, Length: 221\n",
            "Episode: 94\n",
            "Step: 10706, Return: -69.87, Length: 506\n",
            "Episode: 95\n",
            "Step: 11067, Return: -52.31, Length: 361\n",
            "Episode: 96\n",
            "Step: 11610, Return: -241.66, Length: 543\n",
            "Episode: 97\n",
            "Step: 11928, Return: -271.14, Length: 318\n",
            "Episode: 98\n",
            "Step: 12648, Return: -141.62, Length: 720\n",
            "Episode: 99\n",
            "Step: 12903, Return: -37.71, Length: 255\n",
            "Episode: 100\n",
            "Step: 13183, Return: -87.83, Length: 280\n",
            "\n",
            "--- Средний возврат за последние 100 эпизодов: -207.79 ---\n",
            "\n",
            "Episode: 101\n",
            "Step: 13682, Return: -219.47, Length: 499\n",
            "Episode: 102\n",
            "Step: 14682, Return: -46.98, Length: 1000\n",
            "Episode: 103\n",
            "Step: 14839, Return: -57.92, Length: 157\n",
            "Episode: 104\n",
            "Step: 15117, Return: -62.47, Length: 278\n",
            "Episode: 105\n",
            "Step: 15550, Return: -16.52, Length: 433\n",
            "Episode: 106\n",
            "Step: 16550, Return: -42.67, Length: 1000\n",
            "Episode: 107\n",
            "Step: 17550, Return: 0.99, Length: 1000\n",
            "Episode: 108\n",
            "Step: 18550, Return: 16.31, Length: 1000\n",
            "Episode: 109\n",
            "Step: 19550, Return: 1.84, Length: 1000\n",
            "Episode: 110\n",
            "Step: 20369, Return: -208.16, Length: 819\n",
            "Episode: 111\n",
            "Step: 21369, Return: -118.98, Length: 1000\n",
            "Episode: 112\n",
            "Step: 22369, Return: -44.21, Length: 1000\n",
            "Episode: 113\n",
            "Step: 23369, Return: -23.21, Length: 1000\n",
            "Episode: 114\n",
            "Step: 24369, Return: -25.12, Length: 1000\n",
            "Episode: 115\n",
            "Step: 25369, Return: -17.75, Length: 1000\n",
            "Episode: 116\n",
            "Step: 26369, Return: -31.82, Length: 1000\n",
            "Episode: 117\n",
            "Step: 27369, Return: -47.40, Length: 1000\n",
            "Episode: 118\n",
            "Step: 28369, Return: -84.42, Length: 1000\n",
            "Episode: 119\n",
            "Step: 29139, Return: -157.12, Length: 770\n",
            "Episode: 120\n",
            "Step: 29985, Return: -248.09, Length: 846\n",
            "Episode: 121\n",
            "Step: 30802, Return: -148.89, Length: 817\n",
            "Episode: 122\n",
            "Step: 31802, Return: -47.55, Length: 1000\n",
            "Episode: 123\n",
            "Step: 32802, Return: -6.18, Length: 1000\n",
            "Episode: 124\n",
            "Step: 33802, Return: -68.30, Length: 1000\n",
            "Episode: 125\n",
            "Step: 34802, Return: -29.52, Length: 1000\n",
            "Episode: 126\n",
            "Step: 35802, Return: -39.40, Length: 1000\n",
            "Episode: 127\n",
            "Step: 36802, Return: -52.05, Length: 1000\n",
            "Episode: 128\n",
            "Step: 37802, Return: 1.13, Length: 1000\n",
            "Episode: 129\n",
            "Step: 38802, Return: -29.42, Length: 1000\n",
            "Episode: 130\n",
            "Step: 39802, Return: -91.58, Length: 1000\n",
            "Episode: 131\n",
            "Step: 40802, Return: -98.15, Length: 1000\n",
            "Episode: 132\n",
            "Step: 41802, Return: -62.27, Length: 1000\n",
            "Episode: 133\n",
            "Step: 42802, Return: -74.34, Length: 1000\n",
            "Episode: 134\n",
            "Step: 43802, Return: 2.32, Length: 1000\n",
            "Episode: 135\n",
            "Step: 44802, Return: -1.02, Length: 1000\n",
            "Episode: 136\n",
            "Step: 45802, Return: -55.19, Length: 1000\n",
            "Episode: 137\n",
            "Step: 46802, Return: -41.84, Length: 1000\n",
            "Episode: 138\n",
            "Step: 47802, Return: -19.25, Length: 1000\n",
            "Episode: 139\n",
            "Step: 48802, Return: -35.83, Length: 1000\n",
            "Episode: 140\n",
            "Step: 49761, Return: -178.38, Length: 959\n",
            "Episode: 141\n",
            "Step: 50761, Return: -21.23, Length: 1000\n",
            "Episode: 142\n",
            "Step: 51761, Return: -56.77, Length: 1000\n",
            "Episode: 143\n",
            "Step: 52761, Return: 19.87, Length: 1000\n",
            "Episode: 144\n",
            "Step: 53761, Return: 5.10, Length: 1000\n",
            "Episode: 145\n",
            "Step: 54761, Return: -60.52, Length: 1000\n",
            "Episode: 146\n",
            "Step: 55761, Return: -81.77, Length: 1000\n",
            "Episode: 147\n",
            "Step: 56761, Return: 6.73, Length: 1000\n",
            "Episode: 148\n",
            "Step: 57761, Return: -12.79, Length: 1000\n",
            "Episode: 149\n",
            "Step: 58761, Return: 1.72, Length: 1000\n",
            "Episode: 150\n",
            "Step: 59680, Return: -171.07, Length: 919\n",
            "Episode: 151\n",
            "Step: 60591, Return: -185.04, Length: 911\n",
            "Episode: 152\n",
            "Step: 61591, Return: -47.67, Length: 1000\n",
            "Episode: 153\n",
            "Step: 62591, Return: -19.63, Length: 1000\n",
            "Episode: 154\n",
            "Step: 63591, Return: -149.24, Length: 1000\n",
            "Episode: 155\n",
            "Step: 64591, Return: -95.98, Length: 1000\n",
            "Episode: 156\n",
            "Step: 65591, Return: -31.63, Length: 1000\n",
            "Episode: 157\n",
            "Step: 66591, Return: -38.87, Length: 1000\n",
            "Episode: 158\n",
            "Step: 67350, Return: -169.52, Length: 759\n",
            "Episode: 159\n",
            "Step: 68350, Return: -8.61, Length: 1000\n",
            "Episode: 160\n",
            "Step: 69350, Return: -47.66, Length: 1000\n",
            "Episode: 161\n",
            "Step: 70350, Return: -23.80, Length: 1000\n",
            "Episode: 162\n",
            "Step: 71076, Return: -92.79, Length: 726\n",
            "Episode: 163\n",
            "Step: 71841, Return: -139.73, Length: 765\n",
            "Episode: 164\n",
            "Step: 72496, Return: -110.27, Length: 655\n",
            "Episode: 165\n",
            "Step: 73496, Return: -65.32, Length: 1000\n",
            "Episode: 166\n",
            "Step: 74496, Return: -53.52, Length: 1000\n",
            "Episode: 167\n",
            "Step: 75496, Return: -13.90, Length: 1000\n",
            "Episode: 168\n",
            "Step: 76496, Return: -26.80, Length: 1000\n",
            "Episode: 169\n",
            "Step: 77433, Return: -206.06, Length: 937\n",
            "Episode: 170\n",
            "Step: 78433, Return: -21.50, Length: 1000\n",
            "Episode: 171\n",
            "Step: 79433, Return: -46.11, Length: 1000\n",
            "Episode: 172\n",
            "Step: 80433, Return: -60.49, Length: 1000\n",
            "Episode: 173\n",
            "Step: 81433, Return: -58.06, Length: 1000\n",
            "Episode: 174\n",
            "Step: 82433, Return: -87.96, Length: 1000\n",
            "Episode: 175\n",
            "Step: 83433, Return: -65.06, Length: 1000\n",
            "Episode: 176\n",
            "Step: 84433, Return: -19.76, Length: 1000\n",
            "Episode: 177\n",
            "Step: 85433, Return: -26.53, Length: 1000\n",
            "Episode: 178\n",
            "Step: 86433, Return: -11.49, Length: 1000\n",
            "Episode: 179\n",
            "Step: 87433, Return: -18.34, Length: 1000\n",
            "Episode: 180\n",
            "Step: 88433, Return: -81.18, Length: 1000\n",
            "Episode: 181\n",
            "Step: 89433, Return: -34.94, Length: 1000\n",
            "Episode: 182\n",
            "Step: 90433, Return: -16.06, Length: 1000\n",
            "Episode: 183\n",
            "Step: 91433, Return: -40.39, Length: 1000\n",
            "Episode: 184\n",
            "Step: 92433, Return: -50.91, Length: 1000\n",
            "Episode: 185\n",
            "Step: 93433, Return: -45.22, Length: 1000\n",
            "Episode: 186\n",
            "Step: 94433, Return: -44.84, Length: 1000\n",
            "Episode: 187\n",
            "Step: 95433, Return: -27.32, Length: 1000\n",
            "Episode: 188\n",
            "Step: 96433, Return: -71.75, Length: 1000\n",
            "Episode: 189\n",
            "Step: 97433, Return: -32.04, Length: 1000\n",
            "Episode: 190\n",
            "Step: 98433, Return: -71.61, Length: 1000\n",
            "Episode: 191\n",
            "Step: 99433, Return: -28.73, Length: 1000\n",
            "Episode: 192\n",
            "Step: 100433, Return: -37.98, Length: 1000\n",
            "Episode: 193\n",
            "Step: 101433, Return: -44.59, Length: 1000\n",
            "Episode: 194\n",
            "Step: 102315, Return: -289.79, Length: 882\n",
            "Episode: 195\n",
            "Step: 103315, Return: -29.32, Length: 1000\n",
            "Episode: 196\n",
            "Step: 104315, Return: -9.31, Length: 1000\n",
            "Episode: 197\n",
            "Step: 105315, Return: -35.68, Length: 1000\n",
            "Episode: 198\n",
            "Step: 106315, Return: -16.81, Length: 1000\n",
            "Episode: 199\n",
            "Step: 107315, Return: -49.12, Length: 1000\n",
            "Episode: 200\n",
            "Step: 108315, Return: -24.97, Length: 1000\n",
            "\n",
            "--- Средний возврат за последние 100 эпизодов: -59.04 ---\n",
            "\n",
            "Episode: 201\n",
            "Step: 109315, Return: -5.13, Length: 1000\n",
            "Episode: 202\n",
            "Step: 110315, Return: -47.36, Length: 1000\n",
            "Episode: 203\n",
            "Step: 111315, Return: -15.49, Length: 1000\n",
            "Episode: 204\n",
            "Step: 112315, Return: -24.88, Length: 1000\n",
            "Episode: 205\n",
            "Step: 113315, Return: -33.17, Length: 1000\n",
            "Episode: 206\n",
            "Step: 114035, Return: 165.23, Length: 720\n",
            "Episode: 207\n",
            "Step: 115035, Return: -9.90, Length: 1000\n",
            "Episode: 208\n",
            "Step: 115676, Return: 189.32, Length: 641\n",
            "Episode: 209\n",
            "Step: 116676, Return: -16.36, Length: 1000\n",
            "Episode: 210\n",
            "Step: 117676, Return: -13.19, Length: 1000\n",
            "Episode: 211\n",
            "Step: 118676, Return: -0.68, Length: 1000\n",
            "Episode: 212\n",
            "Step: 119676, Return: -30.31, Length: 1000\n",
            "Episode: 213\n",
            "Step: 120676, Return: -38.15, Length: 1000\n",
            "Episode: 214\n",
            "Step: 121676, Return: -42.24, Length: 1000\n",
            "Episode: 215\n",
            "Step: 122676, Return: -76.39, Length: 1000\n",
            "Episode: 216\n",
            "Step: 123676, Return: -73.38, Length: 1000\n",
            "Episode: 217\n",
            "Step: 124676, Return: 25.15, Length: 1000\n",
            "Episode: 218\n",
            "Step: 125676, Return: -26.71, Length: 1000\n",
            "Episode: 219\n",
            "Step: 126676, Return: -42.17, Length: 1000\n",
            "Episode: 220\n",
            "Step: 127565, Return: -277.06, Length: 889\n",
            "Episode: 221\n",
            "Step: 128565, Return: -36.33, Length: 1000\n",
            "Episode: 222\n",
            "Step: 129565, Return: -51.35, Length: 1000\n",
            "Episode: 223\n",
            "Step: 130565, Return: -59.26, Length: 1000\n",
            "Episode: 224\n",
            "Step: 131565, Return: -20.23, Length: 1000\n",
            "Episode: 225\n",
            "Step: 132565, Return: -15.07, Length: 1000\n",
            "Episode: 226\n",
            "Step: 133565, Return: -17.54, Length: 1000\n",
            "Episode: 227\n",
            "Step: 134565, Return: -23.09, Length: 1000\n",
            "Episode: 228\n",
            "Step: 135565, Return: -47.79, Length: 1000\n",
            "Episode: 229\n",
            "Step: 136565, Return: -2.54, Length: 1000\n",
            "Episode: 230\n",
            "Step: 137565, Return: -62.62, Length: 1000\n",
            "Episode: 231\n",
            "Step: 138565, Return: -65.72, Length: 1000\n",
            "Episode: 232\n",
            "Step: 139565, Return: 16.47, Length: 1000\n",
            "Episode: 233\n",
            "Step: 140565, Return: -20.83, Length: 1000\n",
            "Episode: 234\n",
            "Step: 141565, Return: -60.90, Length: 1000\n",
            "Episode: 235\n",
            "Step: 142565, Return: -21.34, Length: 1000\n",
            "Episode: 236\n",
            "Step: 143510, Return: -329.41, Length: 945\n",
            "Episode: 237\n",
            "Step: 144510, Return: 7.71, Length: 1000\n",
            "Episode: 238\n",
            "Step: 145510, Return: 15.89, Length: 1000\n",
            "Episode: 239\n",
            "Step: 146510, Return: 2.13, Length: 1000\n",
            "Episode: 240\n",
            "Step: 147510, Return: -28.52, Length: 1000\n",
            "Episode: 241\n",
            "Step: 148510, Return: 9.27, Length: 1000\n",
            "Episode: 242\n",
            "Step: 149510, Return: 1.24, Length: 1000\n",
            "Episode: 243\n",
            "Step: 150510, Return: -0.98, Length: 1000\n",
            "Episode: 244\n",
            "Step: 151510, Return: -7.84, Length: 1000\n",
            "Episode: 245\n",
            "Step: 152510, Return: -1.08, Length: 1000\n",
            "Episode: 246\n",
            "Step: 153510, Return: -0.77, Length: 1000\n",
            "Episode: 247\n",
            "Step: 154510, Return: 23.83, Length: 1000\n",
            "Episode: 248\n",
            "Step: 155510, Return: -25.83, Length: 1000\n",
            "Episode: 249\n",
            "Step: 156510, Return: -5.85, Length: 1000\n",
            "Episode: 250\n",
            "Step: 157510, Return: 4.76, Length: 1000\n",
            "Episode: 251\n",
            "Step: 158510, Return: 33.45, Length: 1000\n",
            "Episode: 252\n",
            "Step: 159510, Return: -36.27, Length: 1000\n",
            "Episode: 253\n",
            "Step: 160510, Return: -50.74, Length: 1000\n",
            "Episode: 254\n",
            "Step: 161510, Return: -4.58, Length: 1000\n",
            "Episode: 255\n",
            "Step: 162510, Return: 57.99, Length: 1000\n",
            "Episode: 256\n",
            "Step: 163510, Return: -47.49, Length: 1000\n",
            "Episode: 257\n",
            "Step: 164510, Return: -20.42, Length: 1000\n",
            "Episode: 258\n",
            "Step: 164635, Return: -23.22, Length: 125\n",
            "Episode: 259\n",
            "Step: 165635, Return: -19.25, Length: 1000\n",
            "Episode: 260\n",
            "Step: 166635, Return: 29.45, Length: 1000\n",
            "Episode: 261\n",
            "Step: 167635, Return: -17.52, Length: 1000\n",
            "Episode: 262\n",
            "Step: 168635, Return: 7.80, Length: 1000\n",
            "Episode: 263\n",
            "Step: 169543, Return: -120.39, Length: 908\n",
            "Episode: 264\n",
            "Step: 170543, Return: -12.11, Length: 1000\n",
            "Episode: 265\n",
            "Step: 171543, Return: -1.76, Length: 1000\n",
            "Episode: 266\n",
            "Step: 172543, Return: 15.87, Length: 1000\n",
            "Episode: 267\n",
            "Step: 173543, Return: -42.28, Length: 1000\n",
            "Episode: 268\n",
            "Step: 174543, Return: -20.63, Length: 1000\n",
            "Episode: 269\n",
            "Step: 175543, Return: 2.34, Length: 1000\n",
            "Episode: 270\n",
            "Step: 176543, Return: 12.86, Length: 1000\n",
            "Episode: 271\n",
            "Step: 177543, Return: -16.88, Length: 1000\n",
            "Episode: 272\n",
            "Step: 178543, Return: 52.88, Length: 1000\n",
            "Episode: 273\n",
            "Step: 179543, Return: -17.65, Length: 1000\n",
            "Episode: 274\n",
            "Step: 180543, Return: -25.66, Length: 1000\n",
            "Episode: 275\n",
            "Step: 180682, Return: 49.91, Length: 139\n",
            "Episode: 276\n",
            "Step: 181682, Return: -16.51, Length: 1000\n",
            "Episode: 277\n",
            "Step: 182682, Return: -0.90, Length: 1000\n",
            "Episode: 278\n",
            "Step: 183682, Return: 6.66, Length: 1000\n",
            "Episode: 279\n",
            "Step: 184682, Return: 99.67, Length: 1000\n",
            "Episode: 280\n",
            "Step: 185680, Return: 138.98, Length: 998\n",
            "Episode: 281\n",
            "Step: 186680, Return: -34.08, Length: 1000\n",
            "Episode: 282\n",
            "Step: 187680, Return: 58.14, Length: 1000\n",
            "Episode: 283\n",
            "Step: 188680, Return: 4.09, Length: 1000\n",
            "Episode: 284\n",
            "Step: 189491, Return: 140.14, Length: 811\n",
            "Episode: 285\n",
            "Step: 190491, Return: 15.86, Length: 1000\n",
            "Episode: 286\n",
            "Step: 191491, Return: 29.95, Length: 1000\n",
            "Episode: 287\n",
            "Step: 192491, Return: 96.05, Length: 1000\n",
            "Episode: 288\n",
            "Step: 193152, Return: 185.29, Length: 661\n",
            "Episode: 289\n",
            "Step: 194152, Return: 12.17, Length: 1000\n",
            "Episode: 290\n",
            "Step: 195152, Return: 100.59, Length: 1000\n",
            "Episode: 291\n",
            "Step: 196152, Return: 72.11, Length: 1000\n",
            "Episode: 292\n",
            "Step: 197058, Return: 210.23, Length: 906\n",
            "Episode: 293\n",
            "Step: 198058, Return: 43.97, Length: 1000\n",
            "Episode: 294\n",
            "Step: 199047, Return: 185.28, Length: 989\n",
            "Episode: 295\n",
            "Step: 199826, Return: 128.32, Length: 779\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}